{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample training script annotated with explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Constant definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "\n",
    "TRAIN_DATA_DIR = './data/face_10/train'\n",
    "VAL_DATA_DIR = './data/face_10/val'\n",
    "TEST_DATA_DIR = './data/face_10/test'\n",
    "SUBMISSIONS_DIR = './submissions/'\n",
    " \n",
    "INPUT_SIZE = 224  # Alexnet input is 224\n",
    "BATCH_SIZE = 64  #  Mini batch size\n",
    "NUM_CLASSES = 10 # Number of classes for our problem\n",
    "\n",
    "LEARNING_RATE = 1e-2 # Base Learning rate\n",
    "MOMENTUM = 0.9       # SGD momentum\n",
    "WEIGHT_DECAY = 1e-4  # SGD Weight decay\n",
    "EPOCHS = 30          # Total number of epochs to run\n",
    "PRINT_FREQ = 10      # Prints after going through 10 * batch_size samples\n",
    "\n",
    "RESUME_FROM = ''     # Checkpoint to resume training from.\n",
    "FACE_PORT = 1050\n",
    "HOST = 'hvfaceserver-team4'\n",
    "\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import glob\n",
    "\n",
    "def getNextSubmissionId():\n",
    "    a = glob.glob(SUBMISSIONS_DIR+'*.zip')\n",
    "    try:\n",
    "        last = max([int(x.split('/')[-1].split('.')[0]) for x in a])\n",
    "    except:\n",
    "        last = 0\n",
    "    return str(last + 1)\n",
    "\n",
    "def create_submission(preds):\n",
    "    assert preds.dtype=='int'\n",
    "    temp = open(SUBMISSIONS_DIR+'answer.txt', 'w')\n",
    "    for a in range(preds.shape[0]):\n",
    "        print(int(preds[a]), file=temp)\n",
    "    temp.close()\n",
    "    zname = SUBMISSIONS_DIR + getNextSubmissionId()+'.zip'\n",
    "    z = zipfile.ZipFile(zname, 'w')\n",
    "    z.write(SUBMISSIONS_DIR+'answer.txt', 'answer.txt')\n",
    "    z.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading Dataset\n",
    "\n",
    "The following function can be used to load the dataset specified in the folder. This will return two\n",
    "data iterators - one for train and one for val.\n",
    "\n",
    "You can also see the transforms and weights applied to the samples of data while loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def get_train_dataloader():\n",
    "    traindir = TRAIN_DATA_DIR\n",
    "\n",
    "    # Transformations applied to the input data\n",
    "    # while loading.\n",
    "    \n",
    "    # Subtract the mean and divide by variance for each RGB Value\n",
    "    # in the batch.\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(\n",
    "        traindir,\n",
    "        transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.RandomCrop(224), # Taking a random crop of size 224 x 224.\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "    \n",
    "    # Weights governing how likely is one sample over another.\n",
    "    # Check \n",
    "    # - http://pytorch.org/docs/0.3.1/_modules/torch/utils/data/sampler.html#WeightedRandomSampler\n",
    "    # - https://discuss.pytorch.org/t/how-to-prevent-overfitting/1902/25\n",
    "    # for more details.\n",
    "    # Default: Equal weights for all samples.\n",
    "    weights = torch.ones(len(train_dataset)).double()\n",
    "    train_sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(train_dataset))\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=(train_sampler is None),\n",
    "        num_workers=4, \n",
    "        pin_memory=True, \n",
    "        sampler=train_sampler)\n",
    "    \n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    Resize(size=256, interpolation=PIL.Image.BILINEAR)\n",
      "    RandomCrop(size=(224, 224), padding=0)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n",
      "['aamir_khan', 'ajith_kumar', 'anushka', 'deepika_padukone', 'nayanthara', 'priyanka_chopra', 'rajinikanth', 'shahrukh_khan', 'trisha', 'vijay']\n",
      "torch.Size([64, 3, 224, 224]) \n",
      " 4\n",
      " 4\n",
      " 6\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 9\n",
      " 5\n",
      " 8\n",
      " 7\n",
      " 9\n",
      " 7\n",
      " 2\n",
      " 5\n",
      " 7\n",
      " 4\n",
      " 2\n",
      " 5\n",
      " 3\n",
      " 9\n",
      " 9\n",
      " 0\n",
      " 3\n",
      " 7\n",
      " 6\n",
      " 3\n",
      " 2\n",
      " 1\n",
      " 8\n",
      " 4\n",
      " 7\n",
      " 7\n",
      " 1\n",
      " 3\n",
      " 9\n",
      " 6\n",
      " 4\n",
      " 9\n",
      " 3\n",
      " 0\n",
      " 6\n",
      " 1\n",
      " 0\n",
      " 9\n",
      " 9\n",
      " 0\n",
      " 1\n",
      " 4\n",
      " 6\n",
      " 7\n",
      " 6\n",
      " 0\n",
      " 2\n",
      " 6\n",
      " 6\n",
      " 3\n",
      " 8\n",
      " 4\n",
      " 7\n",
      " 0\n",
      " 3\n",
      " 9\n",
      " 4\n",
      " 6\n",
      "[torch.LongTensor of size 64]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader = get_train_dataloader()\n",
    "dataset = train_loader.dataset\n",
    "print(dataset.transform)\n",
    "print(dataset.classes)\n",
    "a=next(iter(train_loader))\n",
    "print(a[0].size(),a[1])  #batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading Alexnet architecture\n",
    "\n",
    "You will find the Alexnet architecture which was discussed in the presentation\n",
    "defined below using `torch.nn` and `torch.nn.Module` modules\n",
    "\n",
    "The pretrained weights are copied into the model wherever the parameter names \n",
    "and sizes match. Else, It is randomly initialized using Xavier Init."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.nn as nn\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), 256 * 6 * 6)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def alexnet(pretrained=False, **kwargs):\n",
    "    r\"\"\"AlexNet model architecture from the\n",
    "    `\"One weird trick...\" <https://arxiv.org/abs/1404.5997>`_ paper.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    url = 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth'\n",
    "    model = AlexNet(**kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(url))\n",
    "    return model\n",
    "\n",
    "def load_alexnet(num_classes, pretrained = True):\n",
    "    \n",
    "    model = alexnet(pretrained=False, num_classes=num_classes)\n",
    "    alexnet_url = 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth'\n",
    "    \n",
    "    if pretrained:\n",
    "      \n",
    "        print(\"=> using pre-trained model '{}'\".format('alexnet'))\n",
    "        print()\n",
    "        \n",
    "        pretrained_state = model_zoo.load_url(alexnet_url)\n",
    "        model_state = model.state_dict()\n",
    "\n",
    "        unfreeze = [ k for k in model_state \n",
    "                        if k not in pretrained_state \n",
    "                        or pretrained_state[k].size() != model_state[k].size() ]\n",
    "        \n",
    "        ignored_states = ','.join([x for x in pretrained_state \n",
    "                                       if x not in model_state])\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "        print(\"--> Ignoring '{}' during restore\".format(ignored_states))\n",
    "        print(\"=\" * 80)\n",
    "        print(\"--> '{}' - Cannot copy parameters due to size mismatch / not present \"\n",
    "              \"in pretrained model. Init with random\".format(','.join([x for x in unfreeze])))\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        pretrained_state = { k:v for k,v in pretrained_state.items() \n",
    "                if k in model_state and v.size() == model_state[k].size() }\n",
    "        \n",
    "        model_state.update(pretrained_state)\n",
    "        model.load_state_dict(model_state)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> using pre-trained model 'alexnet'\n",
      "\n",
      "================================================================================\n",
      "--> Ignoring '' during restore\n",
      "================================================================================\n",
      "--> 'classifier.6.weight,classifier.6.bias' - Cannot copy parameters due to size mismatch / not present in pretrained model. Init with random\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "model=load_alexnet(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.weight torch.Size([64, 3, 11, 11])\n",
      "features.0.bias torch.Size([64])\n",
      "features.3.weight torch.Size([192, 64, 5, 5])\n",
      "features.3.bias torch.Size([192])\n",
      "features.6.weight torch.Size([384, 192, 3, 3])\n",
      "features.6.bias torch.Size([384])\n",
      "features.8.weight torch.Size([256, 384, 3, 3])\n",
      "features.8.bias torch.Size([256])\n",
      "features.10.weight torch.Size([256, 256, 3, 3])\n",
      "features.10.bias torch.Size([256])\n",
      "classifier.1.weight torch.Size([4096, 9216])\n",
      "classifier.1.bias torch.Size([4096])\n",
      "classifier.4.weight torch.Size([4096, 4096])\n",
      "classifier.4.bias torch.Size([4096])\n",
      "classifier.6.weight torch.Size([10, 4096])\n",
      "classifier.6.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in model.named_parameters():\n",
    "    print(p[0],p[1].data.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Utilities\n",
    "\n",
    "For computing moving averages, accuracy and saving the Checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "def save_checkpoint(state, is_best, filename):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, './models/model_best_' + str(NUM_CLASSES) + '_class.pth.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training loop\n",
    "\n",
    "The train function does the following\n",
    "- Loops over the data in an epoch using the data loader\n",
    "- Applies the model on the input to get the output.\n",
    "- Computes the loss for each iteration.\n",
    "- Computes the gradient of loss w.r.t model parameters\n",
    "- Updates the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input = input.cuda()\n",
    "        target = target.cuda(async=True)\n",
    "        input_var = torch.autograd.Variable(input)\n",
    "        target_var = torch.autograd.Variable(target)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n",
    "        losses.update(loss.data[0], input.size(0))\n",
    "        top1.update(prec1[0], input.size(0))\n",
    "        top5.update(prec5[0], input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % PRINT_FREQ == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                  'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                   epoch + 1, i, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1, top5=top5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validation Loop\n",
    "\n",
    "The `validate` function does the following\n",
    "- Iterates over the validation data using the val_loader\n",
    "- Computes the predictions for the validation samples.\n",
    "- Computes the validation loss and validation accuracy.\n",
    "- Returns the validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(val_loader):\n",
    "        \n",
    "        input = input.cuda()\n",
    "        target = target.cuda(async=True)\n",
    "        input_var = torch.autograd.Variable(input, volatile=True)\n",
    "        target_var = torch.autograd.Variable(target, volatile=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n",
    "        losses.update(loss.data[0], input.size(0))\n",
    "        top1.update(prec1[0], input.size(0))\n",
    "        top5.update(prec5[0], input.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % PRINT_FREQ == 0:\n",
    "            print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                  'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1, top5=top5))\n",
    "\n",
    "    print(' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}'\n",
    "          .format(top1=top1, top5=top5))\n",
    "\n",
    "    return top1.avg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### Predictions\n",
    "\n",
    "We need to use our best model to submit predictions on the test data for a given task. The following function does that for you on a batch of test data and returns predictions as a numpy array.\n",
    "\n",
    "- The function accepts the checkpoint path. It will load the model based on the Model architecture defined and copies the weights from the checkpoint file.\n",
    "- The function returns the class predictions for the data in the test dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model_path):\n",
    "    \n",
    "     # Load Model from checkpoint\n",
    "    if(model_path is None):\n",
    "        print('checkpoint argument cannot be None')\n",
    "        return None\n",
    "    \n",
    "    if os.path.isfile(model_path) == False:\n",
    "        print('{} is not found'.format(model_path))\n",
    "        return None\n",
    "    \n",
    "    model = load_alexnet(num_classes = NUM_CLASSES, pretrained=False)\n",
    "    \n",
    "    print(\"=> loading checkpoint '{}'\".format(model_path))\n",
    "    checkpoint = torch.load(model_path)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    print(\"=> loaded model from checkpoint '{}'\".format(model_path))\n",
    "\n",
    "    is_cuda_available = torch.cuda.is_available()\n",
    "    \n",
    "    if is_cuda_available:\n",
    "        model.cuda()\n",
    "        \n",
    "    # test data loader - Keep it similar to val data loader\n",
    "    \n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder(TEST_DATA_DIR, transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])),\n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=False,\n",
    "        num_workers=4, \n",
    "        pin_memory=True)\n",
    "    \n",
    "   \n",
    "    num_batches = len(test_loader)\n",
    "    num_elements = len(test_loader.dataset)\n",
    "    batch_size = test_loader.batch_size\n",
    "\n",
    "    pred_array = torch.zeros(num_elements).long()\n",
    "    prob_array = torch.zeros(num_elements, NUM_CLASSES)\n",
    "\n",
    "    model.train(False)\n",
    "\n",
    "    \n",
    "    for i, data in enumerate(test_loader):\n",
    "        \n",
    "        # Get the indices for each batch\n",
    "        start = i*batch_size\n",
    "        end = start + batch_size\n",
    "        if i == num_batches - 1:\n",
    "            end = num_elements\n",
    "        \n",
    "        inputs, _ = data\n",
    "        \n",
    "        # wrap them in Variable\n",
    "        if is_cuda_available:\n",
    "            inputs = torch.autograd.Variable(inputs.cuda(), volatile=True)\n",
    "        else:\n",
    "            inputs = torch.autograd.Variable(inputs)\n",
    "        \n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # compute output\n",
    "        \n",
    "        pred_array[start:end], prob_array[start:end] = preds.long(), outputs.data\n",
    "\n",
    "    return pred_array.numpy(), prob_array.numpy()\n",
    "\n",
    "def make_submisison_for_model(model_path = './models/model_best_' + str(NUM_CLASSES) + '_class.pth.tar'):\n",
    "    predictions, probabilities = predict(model_path)\n",
    "    create_submission(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NUM_CLASSES' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c86f9c506586>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                            \u001b[0mimg_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                            \u001b[0midx_to_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                            model_path='./models/model_best_' + str(NUM_CLASSES) + '_class.pth.tar'):\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Load Model from checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NUM_CLASSES' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import urllib\n",
    "from urllib import request\n",
    "import socket\n",
    "from socket import *\n",
    "from PIL import Image\n",
    "\n",
    "def get_prediction_for_url(image_url, \n",
    "                           img_transform, \n",
    "                           idx_to_class, \n",
    "                           model_path='./models/model_best_' + str(NUM_CLASSES) + '_class.pth.tar'):\n",
    "    \n",
    "    # Load Model from checkpoint\n",
    "    if(model_path is None):\n",
    "        print('checkpoint argument cannot be None')\n",
    "        return None\n",
    "    \n",
    "    if os.path.isfile(model_path) == False:\n",
    "        print('{} is not found'.format(model_path))\n",
    "        return None\n",
    "    \n",
    "    model = load_alexnet(num_classes = NUM_CLASSES, pretrained=False)\n",
    "    \n",
    "    print(\"=> loading checkpoint '{}'\".format(model_path))\n",
    "    checkpoint = torch.load(model_path)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    print(\"=> loaded model from checkpoint '{}'\".format(model_path))\n",
    "\n",
    "    is_cuda_available = torch.cuda.is_available()\n",
    "    \n",
    "    if is_cuda_available:\n",
    "        model.cuda()\n",
    "\n",
    "    # Download the image from url and save it to disk\n",
    "    f = open('/scratch/input.jpg', 'wb')\n",
    "    f.write(request.urlopen(image_url).read())\n",
    "    f.close()\n",
    "    \n",
    "    # Detect and get aligned face from hvfaceserver\n",
    "    requestJson = {}\n",
    "    requestJson['method'] = '/face/align'\n",
    "    requestJson['image'] = '/scratch/input.jpg'\n",
    "    requestJson['output'] = '/scratch/output.jpg'\n",
    "\n",
    "    # Send a request to the HV Face server\n",
    "    s = socket(AF_INET, SOCK_STREAM)\n",
    "    s.connect((HOST, FACE_PORT))\n",
    "    s.send(json.dumps(requestJson).encode())\n",
    "    recdata = s.recv(200000)\n",
    "    s.close()\n",
    "    \n",
    "    if not recdata:\n",
    "        print('No response received from HV Face Server')\n",
    "        return None\n",
    "    \n",
    "    response = json.loads(recdata)\n",
    "        \n",
    "    if 'error' in response:\n",
    "        print('Error occurred in getting response from HV Face Server for url - {}'.format(response['error']))\n",
    "        return None\n",
    "        \n",
    "    output_image = response['output']\n",
    "    \n",
    "    with open(output_image, 'rb') as f:\n",
    "        img = Image.open(f).convert('RGB')      \n",
    "        \n",
    "    img_tensor = img_transform(img).unsqueeze(0)\n",
    "    \n",
    "    if is_cuda_available:\n",
    "        img_tensor = img_tensor.cuda()\n",
    "    \n",
    "    inputs = torch.autograd.Variable(img_tensor, volatile=True)\n",
    "    outputs = model(inputs)\n",
    "    _, preds = torch.max(outputs.data, 1)\n",
    "    \n",
    "    return idx_to_class[preds.cpu().numpy()[0]]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Putting it all together\n",
    "\n",
    "- Load the datasets and get the dataloaders\n",
    "- Load the model\n",
    "- Decide the loss criterion\n",
    "- Decide the optimizer\n",
    "- Decide the Learning rate schedule.\n",
    "- Train and Validate.\n",
    "- Use best model to predict on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # Load the train loader. Have a look at the function.\n",
    "    train_loader = get_train_dataloader()\n",
    "   \n",
    "    # Here is an example of creating own loader. Useful for loading val\n",
    "    # and test datasets which have similar transforms.\n",
    "    \n",
    "    # define the data directory\n",
    "    val_dir = VAL_DATA_DIR\n",
    "    \n",
    "    # define all the transforms.\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    val_transforms = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "    \n",
    "    # get the loader\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder(val_dir, val_transforms),\n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=False,  # Shuffling not necessary for val and test.\n",
    "        num_workers=4,  \n",
    "        pin_memory=True)\n",
    "    \n",
    " \n",
    "    # Load the pretrained alexnet model repurposed for our NUM_CLASSES\n",
    "    model = load_alexnet(num_classes = NUM_CLASSES, pretrained = True)\n",
    "    \n",
    "    # Using the CrossEntropyLoss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Check if GPU is available.\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "\n",
    "    # Setup the optimizer to track the model parameters to update.\n",
    "    optimizer = torch.optim.SGD(model.parameters(), \n",
    "                                LEARNING_RATE,\n",
    "                                momentum=MOMENTUM,\n",
    "                                weight_decay=WEIGHT_DECAY)\n",
    "    \n",
    "    \n",
    "    start_epoch = 0\n",
    "    best_prec1 = 0;\n",
    "    \n",
    "    # Resume from checkpoint. Useful if you are pausing the training to\n",
    "    # change certain hyperparameters ( data, base learning rate)\n",
    "    \n",
    "    if RESUME_FROM:\n",
    "        if os.path.isfile(RESUME_FROM):\n",
    "            print(\"=> loading checkpoint '{}'\".format(RESUME_FROM))\n",
    "            checkpoint = torch.load(RESUME_FROM)\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(RESUME_FROM, checkpoint['epoch']))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(RESUME_FROM))\n",
    "    \n",
    "    # setting up the learning rate schedule - how it should change\n",
    "    # as learning progresses. Check out other schedulers on the PyTorch\n",
    "    # Documentation website\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, \n",
    "                                    step_size=15, \n",
    "                                    gamma=0.1, \n",
    "                                    last_epoch=(start_epoch - 1))\n",
    "    \n",
    "    # Lets roll!\n",
    "    for epoch in range(start_epoch, EPOCHS):\n",
    "        # Call the learning rate scheduler every epoch to\n",
    "        # update learning rate if necessary.\n",
    "        scheduler.step()\n",
    "\n",
    "        # train for one epoch\n",
    "        train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        prec1 = validate(val_loader, model, criterion)\n",
    "\n",
    "        # remember best prec@1 and save checkpoint\n",
    "        # if it is atleast 80%\n",
    "        \n",
    "        is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "        if best_prec1 > 70:\n",
    "            save_checkpoint({\n",
    "                'epoch': epoch + 1,\n",
    "                'arch': 'alexnet',\n",
    "                'state_dict': model.state_dict(),\n",
    "                'best_prec1': best_prec1,\n",
    "                'optimizer' : optimizer.state_dict(),\n",
    "            }, is_best, filename = './models/checkpoint_' + str(NUM_CLASSES) + '_class.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> using pre-trained model 'alexnet'\n",
      "\n",
      "================================================================================\n",
      "--> Ignoring '' during restore\n",
      "================================================================================\n",
      "--> 'classifier.6.weight,classifier.6.bias' - Cannot copy parameters due to size mismatch / not present in pretrained model. Init with random\n",
      "================================================================================\n",
      "Epoch: [1][0/32]\tTime 0.323 (0.323)\tData 0.283 (0.283)\tLoss 2.7129 (2.7129)\tPrec@1 3.125 (3.125)\tPrec@5 37.500 (37.500)\n",
      "Epoch: [1][10/32]\tTime 0.098 (0.121)\tData 0.000 (0.026)\tLoss 1.9457 (2.2186)\tPrec@1 28.125 (20.455)\tPrec@5 75.000 (62.784)\n",
      "Epoch: [1][20/32]\tTime 0.105 (0.112)\tData 0.000 (0.014)\tLoss 2.4174 (2.0820)\tPrec@1 28.125 (24.405)\tPrec@5 81.250 (72.173)\n",
      "Epoch: [1][30/32]\tTime 0.104 (0.108)\tData 0.000 (0.009)\tLoss 2.4671 (2.1629)\tPrec@1 9.375 (21.774)\tPrec@5 68.750 (70.565)\n",
      "Test: [0/7]\tTime 0.433 (0.433)\tLoss 2.0088 (2.0088)\tPrec@1 40.625 (40.625)\tPrec@5 100.000 (100.000)\n",
      " * Prec@1 12.000 Prec@5 49.500\n",
      "Epoch: [2][0/32]\tTime 0.346 (0.346)\tData 0.303 (0.303)\tLoss 2.3446 (2.3446)\tPrec@1 6.250 (6.250)\tPrec@5 50.000 (50.000)\n",
      "Epoch: [2][10/32]\tTime 0.101 (0.124)\tData 0.000 (0.029)\tLoss 2.5231 (2.6967)\tPrec@1 3.125 (15.057)\tPrec@5 37.500 (51.989)\n",
      "Epoch: [2][20/32]\tTime 0.102 (0.113)\tData 0.000 (0.015)\tLoss 2.3841 (3.0495)\tPrec@1 6.250 (11.905)\tPrec@5 53.125 (50.446)\n",
      "Epoch: [2][30/32]\tTime 0.102 (0.109)\tData 0.000 (0.010)\tLoss 2.3006 (27103665879610048512.0000)\tPrec@1 12.500 (11.794)\tPrec@5 50.000 (49.798)\n",
      "Test: [0/7]\tTime 0.292 (0.292)\tLoss 2.3185 (2.3185)\tPrec@1 0.000 (0.000)\tPrec@5 62.500 (62.500)\n",
      " * Prec@1 10.000 Prec@5 50.000\n",
      "Epoch: [3][0/32]\tTime 0.302 (0.302)\tData 0.260 (0.260)\tLoss 2.3029 (2.3029)\tPrec@1 3.125 (3.125)\tPrec@5 50.000 (50.000)\n",
      "Epoch: [3][10/32]\tTime 0.092 (0.115)\tData 0.000 (0.024)\tLoss 2.3244 (2.3039)\tPrec@1 3.125 (10.227)\tPrec@5 34.375 (49.432)\n",
      "Epoch: [3][20/32]\tTime 0.095 (0.107)\tData 0.000 (0.013)\tLoss 2.2925 (2.3050)\tPrec@1 15.625 (9.226)\tPrec@5 50.000 (47.917)\n",
      "Epoch: [3][30/32]\tTime 0.099 (0.104)\tData 0.001 (0.009)\tLoss 2.2970 (2.3058)\tPrec@1 18.750 (9.073)\tPrec@5 50.000 (48.085)\n",
      "Test: [0/7]\tTime 0.335 (0.335)\tLoss 2.3019 (2.3019)\tPrec@1 0.000 (0.000)\tPrec@5 62.500 (62.500)\n",
      " * Prec@1 10.000 Prec@5 50.000\n",
      "Epoch: [4][0/32]\tTime 0.327 (0.327)\tData 0.285 (0.285)\tLoss 2.3067 (2.3067)\tPrec@1 6.250 (6.250)\tPrec@5 43.750 (43.750)\n",
      "Epoch: [4][10/32]\tTime 0.094 (0.118)\tData 0.000 (0.026)\tLoss 2.3009 (2.3073)\tPrec@1 6.250 (9.943)\tPrec@5 46.875 (44.034)\n",
      "Epoch: [4][20/32]\tTime 0.102 (0.108)\tData 0.000 (0.014)\tLoss 2.2879 (2.3042)\tPrec@1 18.750 (10.565)\tPrec@5 59.375 (48.661)\n",
      "Epoch: [4][30/32]\tTime 0.094 (0.105)\tData 0.000 (0.010)\tLoss 2.3073 (2.3039)\tPrec@1 9.375 (10.685)\tPrec@5 50.000 (48.488)\n",
      "Test: [0/7]\tTime 0.326 (0.326)\tLoss 2.3080 (2.3080)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      " * Prec@1 10.000 Prec@5 50.000\n",
      "Epoch: [5][0/32]\tTime 0.330 (0.330)\tData 0.286 (0.286)\tLoss 2.3084 (2.3084)\tPrec@1 9.375 (9.375)\tPrec@5 40.625 (40.625)\n",
      "Epoch: [5][10/32]\tTime 0.099 (0.118)\tData 0.000 (0.026)\tLoss 2.3143 (2.3025)\tPrec@1 9.375 (9.943)\tPrec@5 40.625 (51.705)\n",
      "Epoch: [5][20/32]\tTime 0.095 (0.108)\tData 0.000 (0.014)\tLoss 2.2968 (2.3019)\tPrec@1 12.500 (11.161)\tPrec@5 40.625 (49.851)\n",
      "Epoch: [5][30/32]\tTime 0.099 (0.105)\tData 0.000 (0.010)\tLoss 2.2960 (2.3028)\tPrec@1 15.625 (10.585)\tPrec@5 53.125 (48.790)\n",
      "Test: [0/7]\tTime 0.412 (0.412)\tLoss 2.3153 (2.3153)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      " * Prec@1 10.000 Prec@5 50.000\n",
      "Epoch: [6][0/32]\tTime 0.336 (0.336)\tData 0.292 (0.292)\tLoss 2.2914 (2.2914)\tPrec@1 9.375 (9.375)\tPrec@5 56.250 (56.250)\n",
      "Epoch: [6][10/32]\tTime 0.096 (0.118)\tData 0.000 (0.027)\tLoss 2.3034 (2.3040)\tPrec@1 6.250 (8.523)\tPrec@5 46.875 (50.000)\n",
      "Epoch: [6][20/32]\tTime 0.099 (0.107)\tData 0.000 (0.014)\tLoss 2.2987 (2.3034)\tPrec@1 12.500 (8.482)\tPrec@5 62.500 (50.000)\n",
      "Epoch: [6][30/32]\tTime 0.094 (0.104)\tData 0.000 (0.010)\tLoss 2.2999 (2.3027)\tPrec@1 6.250 (9.274)\tPrec@5 50.000 (50.403)\n",
      "Test: [0/7]\tTime 0.328 (0.328)\tLoss 2.3147 (2.3147)\tPrec@1 0.000 (0.000)\tPrec@5 62.500 (62.500)\n",
      " * Prec@1 10.000 Prec@5 50.000\n",
      "Epoch: [7][0/32]\tTime 0.346 (0.346)\tData 0.307 (0.307)\tLoss 2.3122 (2.3122)\tPrec@1 12.500 (12.500)\tPrec@5 34.375 (34.375)\n",
      "Epoch: [7][10/32]\tTime 0.100 (0.120)\tData 0.000 (0.028)\tLoss 2.3125 (2.3031)\tPrec@1 6.250 (10.511)\tPrec@5 37.500 (50.000)\n",
      "Epoch: [7][20/32]\tTime 0.095 (0.110)\tData 0.000 (0.015)\tLoss 2.3074 (2.3058)\tPrec@1 6.250 (9.821)\tPrec@5 37.500 (48.512)\n",
      "Epoch: [7][30/32]\tTime 0.103 (0.106)\tData 0.000 (0.010)\tLoss 2.2994 (2.3043)\tPrec@1 12.500 (10.786)\tPrec@5 56.250 (50.000)\n",
      "Test: [0/7]\tTime 0.320 (0.320)\tLoss 2.3242 (2.3242)\tPrec@1 0.000 (0.000)\tPrec@5 0.000 (0.000)\n",
      " * Prec@1 10.000 Prec@5 50.000\n",
      "Epoch: [8][0/32]\tTime 0.233 (0.233)\tData 0.192 (0.192)\tLoss 2.3040 (2.3040)\tPrec@1 9.375 (9.375)\tPrec@5 56.250 (56.250)\n",
      "Epoch: [8][10/32]\tTime 0.101 (0.110)\tData 0.000 (0.018)\tLoss 2.3098 (2.3068)\tPrec@1 6.250 (8.239)\tPrec@5 40.625 (46.591)\n",
      "Epoch: [8][20/32]\tTime 0.117 (0.105)\tData 0.000 (0.009)\tLoss 2.3071 (2.3059)\tPrec@1 6.250 (8.780)\tPrec@5 40.625 (47.321)\n",
      "Epoch: [8][30/32]\tTime 0.092 (0.102)\tData 0.000 (0.007)\tLoss 2.3024 (2.3055)\tPrec@1 18.750 (9.173)\tPrec@5 50.000 (47.077)\n",
      "Test: [0/7]\tTime 0.325 (0.325)\tLoss 2.3206 (2.3206)\tPrec@1 0.000 (0.000)\tPrec@5 37.500 (37.500)\n",
      " * Prec@1 10.000 Prec@5 50.000\n",
      "Epoch: [9][0/32]\tTime 0.283 (0.283)\tData 0.241 (0.241)\tLoss 2.3058 (2.3058)\tPrec@1 6.250 (6.250)\tPrec@5 50.000 (50.000)\n",
      "Epoch: [9][10/32]\tTime 0.102 (0.113)\tData 0.001 (0.022)\tLoss 2.2955 (2.3040)\tPrec@1 18.750 (7.386)\tPrec@5 56.250 (50.284)\n",
      "Epoch: [9][20/32]\tTime 0.098 (0.106)\tData 0.000 (0.012)\tLoss 2.2981 (2.3029)\tPrec@1 12.500 (8.036)\tPrec@5 56.250 (52.530)\n",
      "Epoch: [9][30/32]\tTime 0.098 (0.102)\tData 0.000 (0.008)\tLoss 2.3061 (2.3033)\tPrec@1 15.625 (9.073)\tPrec@5 53.125 (51.512)\n",
      "Test: [0/7]\tTime 0.289 (0.289)\tLoss 2.3169 (2.3169)\tPrec@1 0.000 (0.000)\tPrec@5 37.500 (37.500)\n",
      " * Prec@1 10.000 Prec@5 50.000\n",
      "Epoch: [10][0/32]\tTime 0.288 (0.288)\tData 0.244 (0.244)\tLoss 2.2954 (2.2954)\tPrec@1 12.500 (12.500)\tPrec@5 59.375 (59.375)\n",
      "Epoch: [10][10/32]\tTime 0.100 (0.113)\tData 0.000 (0.023)\tLoss 2.2977 (2.3012)\tPrec@1 6.250 (10.227)\tPrec@5 43.750 (50.852)\n",
      "Epoch: [10][20/32]\tTime 0.096 (0.105)\tData 0.000 (0.012)\tLoss 2.2994 (2.3029)\tPrec@1 9.375 (9.524)\tPrec@5 56.250 (49.107)\n",
      "Epoch: [10][30/32]\tTime 0.090 (0.103)\tData 0.000 (0.008)\tLoss 2.2932 (2.3026)\tPrec@1 21.875 (10.685)\tPrec@5 56.250 (49.698)\n",
      "Test: [0/7]\tTime 0.346 (0.346)\tLoss 2.3062 (2.3062)\tPrec@1 0.000 (0.000)\tPrec@5 37.500 (37.500)\n",
      " * Prec@1 10.000 Prec@5 50.000\n",
      "Epoch: [11][0/32]\tTime 0.291 (0.291)\tData 0.250 (0.250)\tLoss 2.3019 (2.3019)\tPrec@1 6.250 (6.250)\tPrec@5 43.750 (43.750)\n",
      "Epoch: [11][10/32]\tTime 0.098 (0.117)\tData 0.000 (0.023)\tLoss 2.2960 (2.3019)\tPrec@1 21.875 (13.352)\tPrec@5 53.125 (51.420)\n",
      "Epoch: [11][20/32]\tTime 0.092 (0.107)\tData 0.000 (0.012)\tLoss 2.2976 (2.3023)\tPrec@1 15.625 (12.649)\tPrec@5 56.250 (51.488)\n",
      "Epoch: [11][30/32]\tTime 0.097 (0.104)\tData 0.000 (0.008)\tLoss 2.3104 (2.3028)\tPrec@1 0.000 (11.391)\tPrec@5 46.875 (51.109)\n",
      "Test: [0/7]\tTime 0.357 (0.357)\tLoss 2.3331 (2.3331)\tPrec@1 0.000 (0.000)\tPrec@5 37.500 (37.500)\n",
      " * Prec@1 10.000 Prec@5 50.000\n",
      "Epoch: [12][0/32]\tTime 0.345 (0.345)\tData 0.303 (0.303)\tLoss 2.2950 (2.2950)\tPrec@1 12.500 (12.500)\tPrec@5 59.375 (59.375)\n",
      "Epoch: [12][10/32]\tTime 0.103 (0.121)\tData 0.000 (0.028)\tLoss 2.2974 (2.3001)\tPrec@1 21.875 (11.080)\tPrec@5 50.000 (55.966)\n",
      "Epoch: [12][20/32]\tTime 0.097 (0.110)\tData 0.000 (0.015)\tLoss 2.3016 (2.3011)\tPrec@1 9.375 (10.119)\tPrec@5 56.250 (54.018)\n",
      "Epoch: [12][30/32]\tTime 0.095 (0.105)\tData 0.000 (0.010)\tLoss 2.3011 (2.3022)\tPrec@1 3.125 (9.375)\tPrec@5 46.875 (51.915)\n",
      "Test: [0/7]\tTime 0.295 (0.295)\tLoss 2.3473 (2.3473)\tPrec@1 0.000 (0.000)\tPrec@5 37.500 (37.500)\n",
      " * Prec@1 10.000 Prec@5 50.000\n",
      "Epoch: [13][0/32]\tTime 0.344 (0.344)\tData 0.306 (0.306)\tLoss 2.3004 (2.3004)\tPrec@1 15.625 (15.625)\tPrec@5 43.750 (43.750)\n",
      "Epoch: [13][10/32]\tTime 0.102 (0.118)\tData 0.000 (0.028)\tLoss 2.3172 (2.3047)\tPrec@1 3.125 (8.239)\tPrec@5 50.000 (47.727)\n",
      "Epoch: [13][20/32]\tTime 0.097 (0.108)\tData 0.000 (0.015)\tLoss 2.3003 (2.3034)\tPrec@1 3.125 (9.524)\tPrec@5 43.750 (48.661)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [13][30/32]\tTime 0.099 (0.104)\tData 0.000 (0.010)\tLoss 2.3068 (2.3051)\tPrec@1 6.250 (9.274)\tPrec@5 56.250 (48.185)\n",
      "Test: [0/7]\tTime 0.303 (0.303)\tLoss 2.3426 (2.3426)\tPrec@1 0.000 (0.000)\tPrec@5 37.500 (37.500)\n",
      " * Prec@1 10.000 Prec@5 50.000\n",
      "Epoch: [14][0/32]\tTime 0.282 (0.282)\tData 0.239 (0.239)\tLoss 2.3146 (2.3146)\tPrec@1 3.125 (3.125)\tPrec@5 46.875 (46.875)\n",
      "Epoch: [14][10/32]\tTime 0.096 (0.114)\tData 0.000 (0.022)\tLoss 2.3069 (2.3057)\tPrec@1 6.250 (8.807)\tPrec@5 46.875 (45.739)\n",
      "Epoch: [14][20/32]\tTime 0.098 (0.106)\tData 0.000 (0.012)\tLoss 2.3076 (2.3034)\tPrec@1 3.125 (10.417)\tPrec@5 37.500 (49.554)\n",
      "Epoch: [14][30/32]\tTime 0.100 (0.104)\tData 0.000 (0.008)\tLoss 2.2928 (2.3029)\tPrec@1 15.625 (10.585)\tPrec@5 59.375 (50.202)\n",
      "Test: [0/7]\tTime 0.311 (0.311)\tLoss 2.3268 (2.3268)\tPrec@1 0.000 (0.000)\tPrec@5 37.500 (37.500)\n",
      " * Prec@1 10.000 Prec@5 50.000\n",
      "Epoch: [15][0/32]\tTime 0.358 (0.358)\tData 0.316 (0.316)\tLoss 2.2912 (2.2912)\tPrec@1 21.875 (21.875)\tPrec@5 53.125 (53.125)\n",
      "Epoch: [15][10/32]\tTime 0.100 (0.121)\tData 0.000 (0.030)\tLoss 2.3159 (2.3064)\tPrec@1 3.125 (11.080)\tPrec@5 37.500 (45.170)\n",
      "Epoch: [15][20/32]\tTime 0.098 (0.110)\tData 0.000 (0.016)\tLoss 2.3032 (2.3055)\tPrec@1 6.250 (9.375)\tPrec@5 43.750 (46.577)\n",
      "Epoch: [15][30/32]\tTime 0.095 (0.106)\tData 0.000 (0.011)\tLoss 2.2958 (2.3041)\tPrec@1 9.375 (9.879)\tPrec@5 50.000 (46.976)\n",
      "Test: [0/7]\tTime 0.349 (0.349)\tLoss 2.3022 (2.3022)\tPrec@1 0.000 (0.000)\tPrec@5 37.500 (37.500)\n",
      " * Prec@1 10.000 Prec@5 50.000\n",
      "Epoch: [16][0/32]\tTime 0.359 (0.359)\tData 0.316 (0.316)\tLoss 2.2965 (2.2965)\tPrec@1 12.500 (12.500)\tPrec@5 62.500 (62.500)\n",
      "Epoch: [16][10/32]\tTime 0.096 (0.121)\tData 0.000 (0.030)\tLoss 2.3019 (2.3029)\tPrec@1 9.375 (9.375)\tPrec@5 46.875 (48.864)\n",
      "Epoch: [16][20/32]\tTime 0.097 (0.111)\tData 0.000 (0.016)\tLoss 2.3129 (2.3039)\tPrec@1 3.125 (9.821)\tPrec@5 40.625 (48.512)\n",
      "Epoch: [16][30/32]\tTime 0.096 (0.107)\tData 0.000 (0.011)\tLoss 2.3050 (2.3034)\tPrec@1 3.125 (9.274)\tPrec@5 65.625 (51.815)\n",
      "Test: [0/7]\tTime 0.292 (0.292)\tLoss 2.3018 (2.3018)\tPrec@1 0.000 (0.000)\tPrec@5 37.500 (37.500)\n",
      " * Prec@1 10.000 Prec@5 50.000\n",
      "Epoch: [17][0/32]\tTime 0.298 (0.298)\tData 0.257 (0.257)\tLoss 2.2922 (2.2922)\tPrec@1 15.625 (15.625)\tPrec@5 62.500 (62.500)\n",
      "Epoch: [17][10/32]\tTime 0.108 (0.116)\tData 0.000 (0.024)\tLoss 2.3088 (2.3021)\tPrec@1 9.375 (11.932)\tPrec@5 50.000 (53.977)\n",
      "Epoch: [17][20/32]\tTime 0.098 (0.107)\tData 0.000 (0.013)\tLoss 2.2976 (2.3017)\tPrec@1 12.500 (11.905)\tPrec@5 53.125 (54.762)\n",
      "Epoch: [17][30/32]\tTime 0.093 (0.104)\tData 0.000 (0.009)\tLoss 2.2959 (2.3020)\tPrec@1 21.875 (11.089)\tPrec@5 56.250 (53.125)\n",
      "Test: [0/7]\tTime 0.319 (0.319)\tLoss 2.3014 (2.3014)\tPrec@1 0.000 (0.000)\tPrec@5 37.500 (37.500)\n",
      " * Prec@1 10.000 Prec@5 50.000\n",
      "Epoch: [18][0/32]\tTime 0.319 (0.319)\tData 0.277 (0.277)\tLoss 2.2960 (2.2960)\tPrec@1 15.625 (15.625)\tPrec@5 62.500 (62.500)\n",
      "Epoch: [18][10/32]\tTime 0.099 (0.118)\tData 0.000 (0.026)\tLoss 2.3024 (2.3005)\tPrec@1 12.500 (11.364)\tPrec@5 50.000 (52.273)\n",
      "Epoch: [18][20/32]\tTime 0.098 (0.108)\tData 0.000 (0.014)\tLoss 2.2944 (2.3004)\tPrec@1 12.500 (10.863)\tPrec@5 59.375 (52.827)\n",
      "Epoch: [18][30/32]\tTime 0.102 (0.105)\tData 0.000 (0.009)\tLoss 2.2990 (2.3007)\tPrec@1 12.500 (10.786)\tPrec@5 50.000 (51.915)\n",
      "Test: [0/7]\tTime 0.293 (0.293)\tLoss 2.3046 (2.3046)\tPrec@1 0.000 (0.000)\tPrec@5 37.500 (37.500)\n",
      " * Prec@1 10.000 Prec@5 50.000\n",
      "Epoch: [19][0/32]\tTime 0.369 (0.369)\tData 0.327 (0.327)\tLoss 2.2890 (2.2890)\tPrec@1 18.750 (18.750)\tPrec@5 68.750 (68.750)\n",
      "Epoch: [19][10/32]\tTime 0.097 (0.122)\tData 0.000 (0.030)\tLoss 2.2964 (2.3010)\tPrec@1 15.625 (11.932)\tPrec@5 50.000 (52.273)\n",
      "Epoch: [19][20/32]\tTime 0.105 (0.110)\tData 0.000 (0.017)\tLoss 2.3035 (2.3030)\tPrec@1 15.625 (11.458)\tPrec@5 46.875 (50.149)\n",
      "Epoch: [19][30/32]\tTime 0.095 (0.106)\tData 0.000 (0.011)\tLoss 2.3119 (2.3030)\tPrec@1 9.375 (11.290)\tPrec@5 34.375 (49.597)\n",
      "Test: [0/7]\tTime 0.292 (0.292)\tLoss 2.3026 (2.3026)\tPrec@1 0.000 (0.000)\tPrec@5 37.500 (37.500)\n",
      " * Prec@1 10.000 Prec@5 50.000\n",
      "Epoch: [20][0/32]\tTime 0.364 (0.364)\tData 0.324 (0.324)\tLoss 2.3134 (2.3134)\tPrec@1 0.000 (0.000)\tPrec@5 34.375 (34.375)\n",
      "Epoch: [20][10/32]\tTime 0.096 (0.122)\tData 0.000 (0.030)\tLoss 2.2982 (2.3048)\tPrec@1 15.625 (9.375)\tPrec@5 56.250 (47.159)\n",
      "Epoch: [20][20/32]\tTime 0.102 (0.111)\tData 0.000 (0.016)\tLoss 2.3042 (2.3044)\tPrec@1 6.250 (9.821)\tPrec@5 43.750 (47.470)\n",
      "Epoch: [20][30/32]\tTime 0.098 (0.106)\tData 0.000 (0.011)\tLoss 2.3041 (2.3044)\tPrec@1 12.500 (9.677)\tPrec@5 43.750 (47.782)\n",
      "Test: [0/7]\tTime 0.386 (0.386)\tLoss 2.3024 (2.3024)\tPrec@1 0.000 (0.000)\tPrec@5 37.500 (37.500)\n",
      " * Prec@1 10.000 Prec@5 50.000\n",
      "Epoch: [21][0/32]\tTime 0.335 (0.335)\tData 0.294 (0.294)\tLoss 2.3053 (2.3053)\tPrec@1 9.375 (9.375)\tPrec@5 40.625 (40.625)\n",
      "Epoch: [21][10/32]\tTime 0.099 (0.116)\tData 0.000 (0.027)\tLoss 2.3068 (2.3030)\tPrec@1 9.375 (11.080)\tPrec@5 46.875 (49.432)\n",
      "Epoch: [21][20/32]\tTime 0.098 (0.108)\tData 0.000 (0.014)\tLoss 2.3003 (2.3018)\tPrec@1 15.625 (11.458)\tPrec@5 53.125 (50.893)\n",
      "Epoch: [21][30/32]\tTime 0.100 (0.104)\tData 0.000 (0.010)\tLoss 2.3120 (2.3027)\tPrec@1 0.000 (10.282)\tPrec@5 37.500 (50.101)\n",
      "Test: [0/7]\tTime 0.454 (0.454)\tLoss 2.3032 (2.3032)\tPrec@1 0.000 (0.000)\tPrec@5 37.500 (37.500)\n",
      " * Prec@1 10.000 Prec@5 50.000\n",
      "Epoch: [22][0/32]\tTime 0.307 (0.307)\tData 0.263 (0.263)\tLoss 2.3077 (2.3077)\tPrec@1 12.500 (12.500)\tPrec@5 46.875 (46.875)\n",
      "Epoch: [22][10/32]\tTime 0.104 (0.116)\tData 0.000 (0.024)\tLoss 2.3081 (2.3028)\tPrec@1 6.250 (10.511)\tPrec@5 50.000 (50.568)\n",
      "Epoch: [22][20/32]\tTime 0.118 (0.108)\tData 0.000 (0.013)\tLoss 2.3029 (2.3035)\tPrec@1 9.375 (10.714)\tPrec@5 50.000 (47.768)\n",
      "Epoch: [22][30/32]\tTime 0.096 (0.103)\tData 0.000 (0.009)\tLoss 2.3076 (2.3031)\tPrec@1 3.125 (10.081)\tPrec@5 43.750 (49.093)\n",
      "Test: [0/7]\tTime 0.328 (0.328)\tLoss 2.3050 (2.3050)\tPrec@1 0.000 (0.000)\tPrec@5 37.500 (37.500)\n",
      " * Prec@1 10.000 Prec@5 50.000\n",
      "Epoch: [23][0/32]\tTime 0.284 (0.284)\tData 0.245 (0.245)\tLoss 2.3082 (2.3082)\tPrec@1 6.250 (6.250)\tPrec@5 50.000 (50.000)\n",
      "Epoch: [23][10/32]\tTime 0.097 (0.113)\tData 0.000 (0.023)\tLoss 2.3061 (2.3023)\tPrec@1 9.375 (9.375)\tPrec@5 46.875 (51.136)\n",
      "Epoch: [23][20/32]\tTime 0.093 (0.105)\tData 0.000 (0.012)\tLoss 2.2973 (2.3022)\tPrec@1 9.375 (10.417)\tPrec@5 62.500 (51.637)\n",
      "Epoch: [23][30/32]\tTime 0.101 (0.103)\tData 0.000 (0.008)\tLoss 2.2958 (2.3024)\tPrec@1 6.250 (10.988)\tPrec@5 62.500 (51.109)\n",
      "Test: [0/7]\tTime 0.316 (0.316)\tLoss 2.3065 (2.3065)\tPrec@1 0.000 (0.000)\tPrec@5 37.500 (37.500)\n",
      " * Prec@1 10.000 Prec@5 50.000\n",
      "Epoch: [24][0/32]\tTime 0.321 (0.321)\tData 0.280 (0.280)\tLoss 2.3036 (2.3036)\tPrec@1 9.375 (9.375)\tPrec@5 56.250 (56.250)\n",
      "Epoch: [24][10/32]\tTime 0.098 (0.116)\tData 0.000 (0.026)\tLoss 2.3060 (2.3040)\tPrec@1 6.250 (7.955)\tPrec@5 50.000 (50.000)\n",
      "Epoch: [24][20/32]\tTime 0.099 (0.107)\tData 0.000 (0.014)\tLoss 2.3007 (2.3042)\tPrec@1 3.125 (7.738)\tPrec@5 65.625 (50.000)\n",
      "Epoch: [24][30/32]\tTime 0.094 (0.104)\tData 0.000 (0.009)\tLoss 2.3105 (2.3034)\tPrec@1 6.250 (8.569)\tPrec@5 40.625 (51.008)\n",
      "Test: [0/7]\tTime 0.308 (0.308)\tLoss 2.3049 (2.3049)\tPrec@1 0.000 (0.000)\tPrec@5 37.500 (37.500)\n",
      " * Prec@1 10.000 Prec@5 50.000\n",
      "Epoch: [25][0/32]\tTime 0.285 (0.285)\tData 0.243 (0.243)\tLoss 2.3074 (2.3074)\tPrec@1 9.375 (9.375)\tPrec@5 46.875 (46.875)\n",
      "Epoch: [25][10/32]\tTime 0.095 (0.112)\tData 0.001 (0.022)\tLoss 2.3034 (2.3016)\tPrec@1 12.500 (13.068)\tPrec@5 37.500 (51.420)\n",
      "Epoch: [25][20/32]\tTime 0.100 (0.105)\tData 0.000 (0.012)\tLoss 2.2894 (2.3018)\tPrec@1 18.750 (12.798)\tPrec@5 65.625 (52.381)\n",
      "Epoch: [25][30/32]\tTime 0.086 (0.102)\tData 0.000 (0.009)\tLoss 2.3052 (2.3020)\tPrec@1 9.375 (12.500)\tPrec@5 46.875 (52.218)\n",
      "Test: [0/7]\tTime 0.315 (0.315)\tLoss 2.3063 (2.3063)\tPrec@1 0.000 (0.000)\tPrec@5 37.500 (37.500)\n",
      " * Prec@1 10.000 Prec@5 50.000\n",
      "Epoch: [26][0/32]\tTime 0.355 (0.355)\tData 0.312 (0.312)\tLoss 2.2907 (2.2907)\tPrec@1 21.875 (21.875)\tPrec@5 62.500 (62.500)\n",
      "Epoch: [26][10/32]\tTime 0.097 (0.120)\tData 0.000 (0.029)\tLoss 2.3055 (2.3014)\tPrec@1 9.375 (10.227)\tPrec@5 53.125 (51.136)\n",
      "Epoch: [26][20/32]\tTime 0.095 (0.110)\tData 0.000 (0.015)\tLoss 2.3099 (2.3035)\tPrec@1 9.375 (9.970)\tPrec@5 40.625 (48.512)\n",
      "Epoch: [26][30/32]\tTime 0.097 (0.106)\tData 0.000 (0.010)\tLoss 2.3097 (2.3032)\tPrec@1 3.125 (9.980)\tPrec@5 43.750 (49.698)\n",
      "Test: [0/7]\tTime 0.303 (0.303)\tLoss 2.3065 (2.3065)\tPrec@1 0.000 (0.000)\tPrec@5 37.500 (37.500)\n",
      " * Prec@1 10.000 Prec@5 50.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [27][0/32]\tTime 0.369 (0.369)\tData 0.324 (0.324)\tLoss 2.3028 (2.3028)\tPrec@1 9.375 (9.375)\tPrec@5 56.250 (56.250)\n",
      "Epoch: [27][10/32]\tTime 0.093 (0.120)\tData 0.000 (0.030)\tLoss 2.3052 (2.3028)\tPrec@1 9.375 (9.659)\tPrec@5 46.875 (48.011)\n",
      "Epoch: [27][20/32]\tTime 0.096 (0.110)\tData 0.000 (0.016)\tLoss 2.3018 (2.3019)\tPrec@1 12.500 (9.970)\tPrec@5 43.750 (50.595)\n",
      "Epoch: [27][30/32]\tTime 0.096 (0.106)\tData 0.000 (0.011)\tLoss 2.3033 (2.3024)\tPrec@1 9.375 (9.577)\tPrec@5 46.875 (50.101)\n",
      "Test: [0/7]\tTime 0.369 (0.369)\tLoss 2.3061 (2.3061)\tPrec@1 0.000 (0.000)\tPrec@5 37.500 (37.500)\n",
      " * Prec@1 10.000 Prec@5 50.000\n",
      "Epoch: [28][0/32]\tTime 0.380 (0.380)\tData 0.341 (0.341)\tLoss 2.2980 (2.2980)\tPrec@1 12.500 (12.500)\tPrec@5 53.125 (53.125)\n",
      "Epoch: [28][10/32]\tTime 0.094 (0.121)\tData 0.000 (0.031)\tLoss 2.3041 (2.3003)\tPrec@1 12.500 (11.932)\tPrec@5 43.750 (53.409)\n",
      "Epoch: [28][20/32]\tTime 0.099 (0.110)\tData 0.000 (0.017)\tLoss 2.2902 (2.3017)\tPrec@1 15.625 (11.458)\tPrec@5 65.625 (51.339)\n",
      "Epoch: [28][30/32]\tTime 0.096 (0.106)\tData 0.000 (0.012)\tLoss 2.2964 (2.3019)\tPrec@1 9.375 (11.593)\tPrec@5 68.750 (51.714)\n",
      "Test: [0/7]\tTime 0.316 (0.316)\tLoss 2.3069 (2.3069)\tPrec@1 0.000 (0.000)\tPrec@5 37.500 (37.500)\n",
      " * Prec@1 10.000 Prec@5 50.000\n",
      "Epoch: [29][0/32]\tTime 0.335 (0.335)\tData 0.294 (0.294)\tLoss 2.2975 (2.2975)\tPrec@1 3.125 (3.125)\tPrec@5 56.250 (56.250)\n",
      "Epoch: [29][10/32]\tTime 0.097 (0.117)\tData 0.000 (0.027)\tLoss 2.3120 (2.3021)\tPrec@1 3.125 (10.227)\tPrec@5 31.250 (50.568)\n",
      "Epoch: [29][20/32]\tTime 0.098 (0.107)\tData 0.000 (0.014)\tLoss 2.3038 (2.3047)\tPrec@1 6.250 (9.077)\tPrec@5 59.375 (48.958)\n",
      "Epoch: [29][30/32]\tTime 0.109 (0.104)\tData 0.000 (0.010)\tLoss 2.3058 (2.3042)\tPrec@1 12.500 (9.073)\tPrec@5 46.875 (49.798)\n",
      "Test: [0/7]\tTime 0.348 (0.348)\tLoss 2.3073 (2.3073)\tPrec@1 0.000 (0.000)\tPrec@5 37.500 (37.500)\n",
      " * Prec@1 10.000 Prec@5 50.000\n",
      "Epoch: [30][0/32]\tTime 0.281 (0.281)\tData 0.239 (0.239)\tLoss 2.3032 (2.3032)\tPrec@1 6.250 (6.250)\tPrec@5 59.375 (59.375)\n",
      "Epoch: [30][10/32]\tTime 0.094 (0.115)\tData 0.000 (0.023)\tLoss 2.3070 (2.3022)\tPrec@1 9.375 (11.932)\tPrec@5 46.875 (51.420)\n",
      "Epoch: [30][20/32]\tTime 0.095 (0.107)\tData 0.000 (0.012)\tLoss 2.3012 (2.3033)\tPrec@1 6.250 (10.565)\tPrec@5 53.125 (48.958)\n",
      "Epoch: [30][30/32]\tTime 0.099 (0.104)\tData 0.000 (0.008)\tLoss 2.3063 (2.3026)\tPrec@1 6.250 (10.786)\tPrec@5 43.750 (49.496)\n",
      "Test: [0/7]\tTime 0.308 (0.308)\tLoss 2.3073 (2.3073)\tPrec@1 0.000 (0.000)\tPrec@5 37.500 (37.500)\n",
      " * Prec@1 10.000 Prec@5 50.000\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint './models/model_best_10_class.pth.tar'\n",
      "=> loaded model from checkpoint './models/model_best_10_class.pth.tar'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'rajinikanth'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define all the transforms.\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "img_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "# get the idx_to_class mapping\n",
    "val_dir = VAL_DATA_DIR\n",
    "valset = datasets.ImageFolder(val_dir, None)\n",
    "idx_to_class = {v:k for k,v in valset.class_to_idx.items()}\n",
    "\n",
    "get_prediction_for_url('https://www.hindustantimes.com/rf/image_size_960x540/HT/p2/2017/04/22/Pictures/rajinikanth-2-o_7b65b59c-271c-11e7-b743-a11580b053fc.jpg', \n",
    "                       img_transform,\n",
    "                       idx_to_class,\n",
    "                       model_path='./models/model_best_' + str(NUM_CLASSES) + '_class.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/model_best_100_class.pth.tar is not found\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-7d15fa9ac2f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmake_submisison_for_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./models/model_best_100_class.pth.tar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-137e5dd21eed>\u001b[0m in \u001b[0;36mmake_submisison_for_model\u001b[0;34m(model_path)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_submisison_for_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./models/model_best_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_class.pth.tar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0mcreate_submission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "make_submisison_for_model('./models/model_best_100_class.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
